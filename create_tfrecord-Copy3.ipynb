{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "  \"\"\"Wrapper for inserting int64 features into Example proto.\"\"\"\n",
    "  if not isinstance(value, list):\n",
    "    value = [value]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _floats_feature(value):\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=value.reshape(-1)))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Wrapper for inserting bytes features into Example proto.\"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _check_or_create_dir(directory):\n",
    "  \"\"\"Check if directory exists otherwise create it.\"\"\"\n",
    "  if not tf.gfile.Exists(directory):\n",
    "    tf.gfile.MakeDirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_example(filename, image_buffer, label, height, width):\n",
    "  \"\"\"Build an Example proto for an example.\n",
    "\n",
    "  Args:\n",
    "    filename: string, path to an image file, e.g., '/path/to/example.JPG'\n",
    "    image_buffer: string, JPEG encoding of RGB image\n",
    "    label: list, identifier for the ground truth for the network\n",
    "    height: integer, image height in pixels\n",
    "    width: integer, image width in pixels\n",
    "  Returns:\n",
    "    Example proto\n",
    "  \"\"\"\n",
    "  colorspace = b'RGB'\n",
    "  channels = 3\n",
    "  image_format = b'JPEG'\n",
    "\n",
    "  example = tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': _int64_feature(height),\n",
    "      'image/width': _int64_feature(width),\n",
    "      'image/colorspace': _bytes_feature(colorspace),\n",
    "      'image/channels': _int64_feature(channels),\n",
    "      'image/label': _floats_feature(label),\n",
    "      'image/format': _bytes_feature(image_format),\n",
    "      'image/encoded': _bytes_feature(image_buffer)}))\n",
    "  return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCoder(object):\n",
    "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    # Create a single Session to run all image coding calls.\n",
    "    self._sess = tf.Session()\n",
    "\n",
    "    # Initializes function that decodes RGB JPEG data.\n",
    "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "\n",
    "  def decode_jpeg(self, image_data):\n",
    "    image = self._sess.run(self._decode_jpeg,\n",
    "                           feed_dict={self._decode_jpeg_data: image_data})\n",
    "    assert len(image.shape) == 3\n",
    "    assert image.shape[2] == 3\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(filename, coder):\n",
    "  \"\"\"Process a single image file.\n",
    "\n",
    "  Args:\n",
    "    filename: string, path to an image file e.g., '/path/to/example.JPG'.\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "  Returns:\n",
    "    image_buffer: string, JPEG encoding of RGB image.\n",
    "    height: integer, image height in pixels.\n",
    "    width: integer, image width in pixels.\n",
    "  \"\"\"\n",
    "  # Read the image file.\n",
    "  filename = path+filename\n",
    "  with tf.gfile.FastGFile(filename, 'rb') as f:\n",
    "    image_data = f.read()\n",
    "  \n",
    "\n",
    "  # Decode the RGB JPEG.\n",
    "  image = coder.decode_jpeg(image_data)\n",
    "  image = tf.image.resize_images(image, (256,256))\n",
    "  \n",
    "  # Check that image converted to RGB\n",
    "  assert len(image.shape) == 3\n",
    "  height = image.shape[0]\n",
    "  width = image.shape[1]\n",
    "  assert image.shape[2] == 3\n",
    "\n",
    "  return image_data, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image_files_batch(coder, output_file, filenames, labels):\n",
    "  \"\"\"Processes and saves list of images as TFRecords.\n",
    "  Args:\n",
    "    coder: instance of ImageCoder to provide TensorFlow image coding utils.\n",
    "    output_file: string, unique identifier specifying the data set\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "  \"\"\"\n",
    "  writer = tf.python_io.TFRecordWriter(output_file)\n",
    "\n",
    "  for filename, label in zip(filenames, labels):\n",
    "    image_buffer, height, width = _process_image(filename, coder)\n",
    "    example = _convert_to_example(filename, image_buffer, label,\n",
    "                                   height, width)\n",
    "    writer.write(example.SerializeToString())\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_dataset(filenames, labels, output_directory, prefix,\n",
    "                     num_shards):\n",
    "  \"\"\"Processes and saves list of images as TFRecords.\n",
    "\n",
    "  Args:\n",
    "    filenames: list of strings; each string is a path to an image file\n",
    "    synsets: list of strings; each string is a unique WordNet ID\n",
    "    labels: map of string to integer; id for all synset labels\n",
    "    output_directory: path where output files should be created\n",
    "    prefix: string; prefix for each file\n",
    "    num_shards: number of chucks to split the filenames into\n",
    "\n",
    "  Returns:\n",
    "    files: list of tf-record filepaths created from processing the dataset.\n",
    "  \"\"\"\n",
    "  _check_or_create_dir(output_directory)\n",
    "  chunksize = int(math.ceil(len(filenames) / num_shards))\n",
    "  coder = ImageCoder()\n",
    "\n",
    "  files = []\n",
    "\n",
    "  for shard in range(num_shards):\n",
    "    chunk_files = filenames[shard * chunksize : (shard + 1) * chunksize]\n",
    "    output_file = os.path.join(\n",
    "        output_directory, '%s-%.5d-of-%.5d' % (prefix, shard, num_shards))\n",
    "    _process_image_files_batch(coder, output_file, chunk_files,\n",
    "                               labels)\n",
    "    tf.logging.info('Finished writing file: %s' % output_file)\n",
    "    files.append(output_file)\n",
    "  return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+'./CheXpert-v1.0-small/train.csv')\n",
    "valid = pd.read_csv(path+'./CheXpert-v1.0-small/valid.csv')\n",
    "\n",
    "train['validation'] = False\n",
    "valid['validation'] = True\n",
    "df = pd.concat([train, valid])\n",
    "\n",
    "columns = ['Path', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'validation']\n",
    "df = df[columns]\n",
    "\n",
    "for feature in ['Atelectasis', 'Edema']:\n",
    "    df[feature] = df[feature].apply(lambda x: 1 if x==-1 else x)\n",
    "\n",
    "for feature in ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']:\n",
    "    df[feature] = df[feature].apply(lambda x: 0 if x==-1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00001/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study2/...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00002/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CheXpert-v1.0-small/train/patient00003/study1/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  Atelectasis  \\\n",
       "0  CheXpert-v1.0-small/train/patient00001/study1/...          0.0   \n",
       "1  CheXpert-v1.0-small/train/patient00002/study2/...          1.0   \n",
       "2  CheXpert-v1.0-small/train/patient00002/study1/...          0.0   \n",
       "3  CheXpert-v1.0-small/train/patient00002/study1/...          0.0   \n",
       "4  CheXpert-v1.0-small/train/patient00003/study1/...          0.0   \n",
       "\n",
       "   Cardiomegaly  Consolidation  Edema  Pleural Effusion  validation  \n",
       "0           0.0            0.0    0.0               0.0       False  \n",
       "1           0.0            0.0    1.0               0.0       False  \n",
       "2           0.0            0.0    0.0               0.0       False  \n",
       "3           0.0            0.0    0.0               0.0       False  \n",
       "4           0.0            0.0    1.0               0.0       False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tf_records(_df, out_dir = './tfrecord_test'):\n",
    "  \"\"\"Convert the Imagenet dataset into TF-Record dumps.\"\"\"\n",
    "\n",
    "  # Shuffle training records to ensure we are distributing classes\n",
    "  # across the batches.\n",
    "  random.seed(0)\n",
    "  def make_shuffle_idx(n):\n",
    "    order = range(n)\n",
    "    random.shuffle(order)\n",
    "    return order\n",
    "  \n",
    "  columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "  train = _df[~_df.validation][100000:150000]\n",
    "  print(len(train))\n",
    "  training_files = train['Path'].tolist()\n",
    "  training_labels = np.array(train[columns])\n",
    "  \n",
    "  valid = _df[_df.validation]\n",
    "  validation_files = valid['Path'].tolist()\n",
    "  validation_labels = np.array(valid[columns])\n",
    "  \n",
    "  # Create training data\n",
    "  tf.logging.info('Processing the training data.')\n",
    "  training_records = _process_dataset(\n",
    "      training_files, training_labels, out_dir,\n",
    "      TRAINING_DIRECTORY, TRAINING_SHARDS)\n",
    "\n",
    "#   # Create validation data\n",
    "#   tf.logging.info('Processing the validation data.')\n",
    "#   validation_records = _process_dataset(\n",
    "#       validation_files, validation_labels, out_dir,\n",
    "#       VALIDATION_DIRECTORY, VALIDATION_SHARDS)\n",
    "\n",
    "  return training_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SHARDS = 32\n",
    "VALIDATION_SHARDS = 16\n",
    "\n",
    "TRAINING_DIRECTORY = 'train'\n",
    "VALIDATION_DIRECTORY = 'valid'\n",
    "\n",
    "path = './../../../../main/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0620 13:02:48.795705 139990059136832 deprecation.py:323] From <ipython-input-6-d951683fb5f4>:14: __init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "training_records = convert_to_tf_records(_df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "for example in tf.python_io.tf_record_iterator(\"./tfrecord_out/train-00000-of-00032\"):\n",
    "    result = tf.train.Example.FromString(example)\n",
    "    print('l')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
