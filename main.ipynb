{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Eval checkpoint driver.\n",
    "\n",
    "This is an example evaluation script for users to understand the EfficientNet\n",
    "model checkpoints on CPU. To serve EfficientNet, please consider to export a\n",
    "`SavedModel` from checkpoints and use tf-serving to serve.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "import efficientnet_builder\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "# flags.DEFINE_string('model_name', 'efficientnet-b0', 'Model name to eval.')\n",
    "# flags.DEFINE_string('runmode', 'examples', 'Running mode: examples or imagenet')\n",
    "# flags.DEFINE_string('imagenet_eval_glob', None,\n",
    "#                     'Imagenet eval image glob, '\n",
    "#                     'such as /imagenet/ILSVRC2012*.JPEG')\n",
    "# flags.DEFINE_string('imagenet_eval_label', None,\n",
    "#                     'Imagenet eval label file path, '\n",
    "#                     'such as /imagenet/ILSVRC2012_validation_ground_truth.txt')\n",
    "# flags.DEFINE_string('ckpt_dir', '/tmp/ckpt/', 'Checkpoint folders')\n",
    "# flags.DEFINE_string('example_img', '/tmp/panda.jpg',\n",
    "#                     'Filepath for a single example image.')\n",
    "# flags.DEFINE_string('labels_map_file', '/tmp/labels_map.txt',\n",
    "#                     'Labels map from label id to its meaning.')\n",
    "# flags.DEFINE_integer('num_images', 5000,\n",
    "#                      'Number of images to eval. Use -1 to eval all images.')\n",
    "# FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size 224\n"
     ]
    }
   ],
   "source": [
    "MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "\n",
    "\n",
    "model_name='efficientnet-b0'\n",
    "batch_size=16\n",
    "\"\"\"Initialize internal variables.\"\"\"\n",
    "model_name = model_name\n",
    "batch_size = batch_size\n",
    "num_classes = 1000\n",
    "# Model Scaling parameters\n",
    "_, _, image_size, _ = efficientnet_builder.efficientnet_params(\n",
    "      model_name)\n",
    "print('image_size', image_size)\n",
    "\n",
    "def restore_model(sess, ckpt_dir):\n",
    "  \"\"\"Restore variables from checkpoint dir.\"\"\"\n",
    "  checkpoint = tf.train.latest_checkpoint(ckpt_dir)\n",
    "  ema = tf.train.ExponentialMovingAverage(decay=0.9999)\n",
    "  ema_vars = tf.trainable_variables() + tf.get_collection('moving_vars')\n",
    "  for v in tf.global_variables():\n",
    "    if 'moving_mean' in v.name or 'moving_variance' in v.name:\n",
    "      ema_vars.append(v)\n",
    "  ema_vars = list(set(ema_vars))\n",
    "  var_dict = ema.variables_to_restore(ema_vars)\n",
    "  saver = tf.train.Saver(var_dict, max_to_keep=1)\n",
    "  saver.restore(sess, checkpoint)\n",
    "\n",
    "def build_model( features, is_training):\n",
    "  \"\"\"Build model with input features.\"\"\"\n",
    "#   features -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=features.dtype)\n",
    "#   features /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=features.dtype)\n",
    "  out, _ = efficientnet_builder.build_model_base(\n",
    "      features, model_name, is_training)\n",
    "  return out\n",
    "\n",
    "def build_dataset(filenames, labels, is_training):\n",
    "  \"\"\"Build input dataset.\"\"\"\n",
    "  filenames = tf.constant(filenames)\n",
    "  labels = tf.constant(labels)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "\n",
    "  def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "    image_decoded = preprocessing.preprocess_image(\n",
    "        image_string, is_training, image_size=image_size)\n",
    "    image = tf.cast(image_decoded, tf.float32)\n",
    "    return image, label\n",
    "\n",
    "  dataset = dataset.map(_parse_function)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "\n",
    "  iterator = dataset.make_one_shot_iterator()\n",
    "  images, labels = iterator.get_next()\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 00:05:51.039052 4739323328 image.py:656] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "(4, 224, 224, 3) tf.Tensor(\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]], shape=(4, 5), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_images(dataset, n_images, samples_per_image):\n",
    "    output = np.zeros((32 * n_images, 32 * samples_per_image, 3))\n",
    "\n",
    "    row = 0\n",
    "    for images, labls in dataset.repeat(samples_per_image).batch(n_images):\n",
    "        print(images.shape, labls)\n",
    "        break\n",
    "#         output[:, row*32:(row+1)*32] = np.vstack(images.numpy())\n",
    "#         row += 1\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "training_files, labels = get_data()    \n",
    "training_files = tf.constant(training_files)\n",
    "labels = tf.constant(labels, shape=[234, 5])\n",
    "dataset = tf.data.Dataset.from_tensor_slices((training_files, labels))\n",
    "def _parse_function(filename, label):\n",
    "  image_string = tf.read_file(filename)\n",
    "  image_decoded = preprocessing.preprocess_image(\n",
    "      image_string, False, image_size=image_size)\n",
    "  image = tf.cast(image_decoded, tf.float32)\n",
    "  return image, label\n",
    "\n",
    "dataset = dataset.map(_parse_function)\n",
    "plot_images(dataset, n_images=4, samples_per_image=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.1875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.06187500e+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 00:06:13.836422 4739323328 deprecation.py:506] From /Users/midhunpk/Documents/artelus/efficientnet/lib/python2.7/site-packages/tensorflow/python/framework/function.py:1007: calling create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Shapes are always computed; don't use the compute_shapes as it has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n",
      "###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0621 00:07:36.610641 4739323328 deprecation.py:323] From /Users/midhunpk/Documents/artelus/efficientnet/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0621 00:07:36.939127 4739323328 deprecation.py:323] From <ipython-input-52-12efab96f1e1>:10: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "W0621 00:07:36.962785 4739323328 deprecation.py:323] From /Users/midhunpk/Documents/artelus/efficientnet/lib/python2.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0621 00:07:37.255400 4739323328 deprecation.py:323] From /Users/midhunpk/Documents/artelus/efficientnet/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0621 00:07:42.034029 4739323328 deprecation.py:323] From /Users/midhunpk/Documents/artelus/efficientnet/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0415505\n",
      "1.0326006\n",
      "1.0754901\n",
      "1.0489991\n",
      "0.9445638\n",
      "0.8205646\n",
      "0.9939699\n",
      "0.75426775\n",
      "0.7495252\n",
      "0.74650896\n",
      "0.74362624\n",
      "0.7412493\n",
      "0.8382993\n",
      "0.81164426\n"
     ]
    }
   ],
   "source": [
    "training_files, labels = get_data()\n",
    "graph = tf.Graph()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "  images, labels = build_dataset(training_files, labels, False)\n",
    "  out = build_model(images, is_training=False)\n",
    "  out = tf.reduce_mean(out, axis=[1,2])\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  restore_model(sess, './weights_efficientnet-b0/')\n",
    "  \n",
    "  temp = set(tf.all_variables())\n",
    "  \n",
    "  logits = tf.contrib.layers.fully_connected(out, 5, activation_fn=None)\n",
    "\n",
    "  logits = tf.math.sigmoid(logits, name = 'sigmoid_logits')\n",
    "  cross_entropy = tf.losses.sigmoid_cross_entropy(logits=logits,\n",
    "                                                  multi_class_labels=labels)\n",
    "  weight_decay = 1e-5\n",
    "  loss = cross_entropy + weight_decay * tf.add_n(\n",
    "      [tf.nn.l2_loss(v) for v in tf.trainable_variables()\n",
    "       if 'batch_normalization' not in v.name])\n",
    "  \n",
    "  lr = 0.01\n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=lr, name=\"adam\").minimize(loss)\n",
    "  \n",
    "  sess.run(tf.initialize_variables(set(tf.all_variables()) - temp))\n",
    "  for i in range(len(training_files)//batch_size):\n",
    "    lss, _ = sess.run([loss, optimizer])\n",
    "    print(lss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('file4.npy', np.array(out_probs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for op in graph.get_operations():\n",
    "     print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(out_probs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_data():\n",
    "  path = './'\n",
    "  train = pd.read_csv(path+'./CheXpert-v1.0-small/train.csv')\n",
    "  valid = pd.read_csv(path+'./CheXpert-v1.0-small/valid.csv')\n",
    "  \n",
    "  train['validation'] = False\n",
    "  valid['validation'] = True\n",
    "  df = pd.concat([train, valid])\n",
    "  \n",
    "  columns = ['Path', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion', 'validation']\n",
    "  df = df[columns]\n",
    "  \n",
    "  for feature in ['Atelectasis', 'Edema']:\n",
    "      df[feature] = df[feature].apply(lambda x: 1 if x==-1 else x)\n",
    "  \n",
    "  for feature in ['Cardiomegaly', 'Consolidation', 'Pleural Effusion']:\n",
    "      df[feature] = df[feature].apply(lambda x: 0 if x==-1 else x)\n",
    "  df.fillna(0, inplace=True)\n",
    "  \n",
    "  train = df[~df.validation]\n",
    "  print(len(train))\n",
    "  files = train['Path'].tolist()\n",
    "  files = [path+fil for fil in files]\n",
    "  \n",
    "  columns = ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "  labels = np.array(train[columns])\n",
    "  \n",
    "  return files, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_files = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "efficientnet",
   "language": "python",
   "name": "efficientnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
